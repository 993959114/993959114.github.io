[{"title":"RibbitMQ实战教程","date":"2020-07-30T07:35:11.278Z","path":"2020/07/30/RibbitMQ实战教程/","text":"RabbitMQ 实战教程1.MQ引言1.1 什么是MQMQ(Message Quene)翻译为 消息队列,通过典型的 生产者和消费者模型,生产者不断向消息队列中生产消息，消费者不断的从队列中获取消息。因为消息的生产和消费都是异步的，而且只关心消息的发送和接收，没有业务逻辑的侵入,轻松的实现系统间解耦。别名为 消息中间件 通过利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。 1.2 MQ有哪些当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发RocketMQ等。 1.3 不同MQ特点1234567891011121314151617# 1.ActiveMQ ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。它是一个完全支持JMS规范的的消息中间件。丰富的API,多种集群架构模式让ActiveMQ在业界成为老牌的消息中间件,在中小型企业颇受欢迎!# 2.Kafka Kafka是LinkedIn开源的分布式发布-订阅消息系统，目前归属于Apache顶级项目。Kafka主要特点是基于Pull的模式来处理消息消费， 追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求， 适合产生大量数据的互联网服务的数据收集业务。# 3.RocketMQ RocketMQ是阿里开源的消息中间件，它是纯Java开发，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起 源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消 息推送、日志流式处理、binglog分发等场景。# 4.RabbitMQ RabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由（包括点对点和 发布&#x2F;订阅）、可靠性、安全。AMQP协议更多用在企业系统内对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在 其次。 RabbitMQ比Kafka可靠，Kafka更适合IO高吞吐的处理，一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用，比如ELK日志收集。 2.RabbitMQ 的引言2.1 RabbitMQ 基于AMQP协议，erlang语言开发，是部署最广泛的开源消息中间件,是最受欢迎的开源消息中间件之一。 image-20190925215603036 官网: https://www.rabbitmq.com/ 官方教程: https://www.rabbitmq.com/\\#getstarted 12# AMQP 协议 AMQP（advanced message queuing protocol）&#96;在2003年时被提出，最早用于解决金融领不同平台之间的消息传递交互问题。顾名思义，AMQP是一种协议，更准确的说是一种binary wire-level protocol（链接协议）。这是其和JMS的本质差别，AMQP不从API层进行限定，而是直接定义网络交换的数据格式。这使得实现了AMQP的provider天然性就是跨平台的。以下是AMQP协议模型: image-20200311182438041 2.2 RabbitMQ 的安装2.2.1 下载官网下载地址: https://www.rabbitmq.com/download.html image-20190925220115235 最新版本: 3.7.18 2.2.2 下载的安装包 image-20190925220343521 注意:这里的安装包是centos7安装的包 2.2.3 安装步骤12345678910111213141516171819# 1.将rabbitmq安装包上传到linux系统中 erlang-22.0.7-1.el7.x86_64.rpm rabbitmq-server-3.7.18-1.el7.noarch.rpm# 2.安装Erlang依赖包 rpm -ivh erlang-22.0.7-1.el7.x86_64.rpm# 3.安装RabbitMQ安装包(需要联网) yum install -y rabbitmq-server-3.7.18-1.el7.noarch.rpm 注意:默认安装完成后配置文件模板在:&#x2F;usr&#x2F;share&#x2F;doc&#x2F;rabbitmq-server-3.7.18&#x2F;rabbitmq.config.example目录中,需要 将配置文件复制到&#x2F;etc&#x2F;rabbitmq&#x2F;目录中,并修改名称为rabbitmq.config# 4.复制配置文件 cp &#x2F;usr&#x2F;share&#x2F;doc&#x2F;rabbitmq-server-3.7.18&#x2F;rabbitmq.config.example &#x2F;etc&#x2F;rabbitmq&#x2F;rabbitmq.config# 5.查看配置文件位置 ls &#x2F;etc&#x2F;rabbitmq&#x2F;rabbitmq.config# 6.修改配置文件(参见下图:) vim &#x2F;etc&#x2F;rabbitmq&#x2F;rabbitmq.config image-20190925222230260 将上图中配置文件中红色部分去掉%%,以及最后的,逗号 修改为下图: image-20190925222329200 123456789101112131415161718192021222324252627282930313233343536373839# 7.执行如下命令,启动rabbitmq中的插件管理 rabbitmq-plugins enable rabbitmq_management 出现如下说明: Enabling plugins on node rabbit@localhost: rabbitmq_management The following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatch Applying plugin configuration to rabbit@localhost... The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatch set 3 plugins. Offline change; changes will take effect at broker restart.# 8.启动RabbitMQ的服务 systemctl start rabbitmq-server systemctl restart rabbitmq-server systemctl stop rabbitmq-server # 9.查看服务状态(见下图:) systemctl status rabbitmq-server ● rabbitmq-server.service - RabbitMQ broker Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rabbitmq-server.service; disabled; vendor preset: disabled) Active: active (running) since 三 2019-09-25 22:26:35 CST; 7s ago Main PID: 2904 (beam.smp) Status: &quot;Initialized&quot; CGroup: &#x2F;system.slice&#x2F;rabbitmq-server.service ├─2904 &#x2F;usr&#x2F;lib64&#x2F;erlang&#x2F;erts-10.4.4&#x2F;bin&#x2F;beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf - MBlmbcs... ├─3220 erl_child_setup 32768 ├─3243 inet_gethost 4 └─3244 inet_gethost 4 ......... image-20190925222743776 12345678# 10.关闭防火墙服务 systemctl disable firewalld Removed symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;firewalld.service. Removed symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;dbus-org.fedoraproject.FirewallD1.service. systemctl stop firewalld # 11.访问web管理界面 http:&#x2F;&#x2F;10.15.0.8:15672&#x2F; image-20190926194738708 123# 12.登录管理界面 username: guest password: guest image-20190926194954822 RabiitMQ 配置 3.1RabbitMQ 管理命令行12345678# 1.服务启动相关 systemctl start|restart|stop|status rabbitmq-server# 2.管理命令行 用来在不使用web管理界面情况下命令操作RabbitMQ rabbitmqctl help 可以查看更多命令# 3.插件管理命令行 rabbitmq-plugins enable|list|disable 3.2 web管理界面介绍3.2.1 overview概览 image-20191126162026720 connections：无论生产者还是消费者，都需要与RabbitMQ建立连接后才可以完成消息的生产和消费，在这里可以查看连接情况 channels：通道，建立连接后，会形成通道，消息的投递获取依赖通道。 Exchanges：交换机，用来实现消息的路由 Queues：队列，即消息队列，消息存放在队列中，等待消费，消费后被移除队列。 3.2.2 Admin用户和虚拟主机管理1. 添加用户 image-20191126162617280 上面的Tags选项，其实是指定用户的角色，可选的有以下几个： 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 2. 创建虚拟主机12# 虚拟主机 为了让各个用户可以互不干扰的工作，RabbitMQ添加了虚拟主机（Virtual Hosts）的概念。其实就是一个独立的访问路径，不同用户使用不同路径，各自有自己的队列、交换机，互相不会影响。 image-20191126163023153 3. 绑定虚拟主机和用户创建好虚拟主机，我们还要给用户添加访问权限： 点击添加好的虚拟主机： image-20191126163506795 进入虚拟机设置界面: image-20191126163631889 4.RabbitMQ 的第一个程序4.0 AMQP协议的回顾 image-20200312140114784 4.1 RabbitMQ支持的消息模型 image-20191126165434784 image-20191126165459282 4.2 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;&#x2F;groupId&gt; &lt;artifactId&gt;amqp-client&lt;&#x2F;artifactId&gt; &lt;version&gt;5.7.2&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 4.3 第一种模型(直连) image-20191126165840602 在上图的模型中，有以下概念： P：生产者，也就是要发送消息的程序 C：消费者：消息的接受者，会一直等待消息到来。 queue：消息队列，图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息。 1. 开发生产者123456789101112131415&#x2F;&#x2F;创建连接工厂ConnectionFactory connectionFactory &#x3D; new ConnectionFactory();connectionFactory.setHost(&quot;10.15.0.9&quot;);connectionFactory.setPort(5672);connectionFactory.setUsername(&quot;ems&quot;);connectionFactory.setPassword(&quot;123&quot;);connectionFactory.setVirtualHost(&quot;&#x2F;ems&quot;);Connection connection &#x3D; connectionFactory.newConnection();&#x2F;&#x2F;创建通道Channel channel &#x3D; connection.createChannel();&#x2F;&#x2F;参数1: 是否持久化 参数2:是否独占队列 参数3:是否自动删除 参数4:其他属性channel.queueDeclare(&quot;hello&quot;,true,false,false,null);channel.basicPublish(&quot;&quot;,&quot;hello&quot;, null,&quot;hello rabbitmq&quot;.getBytes());channel.close();connection.close(); 2. 开发消费者12345678910111213141516&#x2F;&#x2F;创建连接工厂ConnectionFactory connectionFactory &#x3D; new ConnectionFactory();connectionFactory.setHost(&quot;10.15.0.9&quot;);connectionFactory.setPort(5672);connectionFactory.setUsername(&quot;ems&quot;);connectionFactory.setPassword(&quot;123&quot;);connectionFactory.setVirtualHost(&quot;&#x2F;ems&quot;);Connection connection &#x3D; connectionFactory.newConnection();Channel channel &#x3D; connection.createChannel();channel.queueDeclare(&quot;hello&quot;, true, false, false, null);channel.basicConsume(&quot;hello&quot;,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(new String(body)); &#125;&#125;); 3. 参数的说明123456channel.queueDeclare(&quot;hello&quot;,true,false,false,null); &#39;参数1&#39;:用来声明通道对应的队列&#39;参数2&#39;:用来指定是否持久化队列&#39;参数3&#39;:用来指定是否独占队列&#39;参数4&#39;:用来指定是否自动删除队列&#39;参数5&#39;:对队列的额外配置 4.4 第二种模型(work quene)Work queues，也被称为（Task queues），任务模型。当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。此时就可以使用work 模型：让多个消费者绑定到一个队列，共同消费队列中的消息。队列中的消息一旦消费，就会消失，因此任务是不会被重复执行的。 image-20200314221002008 角色： P：生产者：任务的发布者 C1：消费者-1，领取任务并且完成任务，假设完成速度较慢 C2：消费者-2：领取任务并完成任务，假设完成速度快 1. 开发生产者1234channel.queueDeclare(&quot;hello&quot;, true, false, false, null);for (int i &#x3D; 0; i &lt; 10; i++) &#123; channel.basicPublish(&quot;&quot;, &quot;hello&quot;, null, (i+&quot;&#x3D;&#x3D;&#x3D;&#x3D;&gt;:我是消息&quot;).getBytes());&#125; 2.开发消费者-11234567channel.queueDeclare(&quot;hello&quot;,true,false,false,null);channel.basicConsume(&quot;hello&quot;,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者1: &quot;+new String(body)); &#125;&#125;); 3.开发消费者-2123456789101112channel.queueDeclare(&quot;hello&quot;,true,false,false,null);channel.basicConsume(&quot;hello&quot;,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; try &#123; Thread.sleep(1000); &#x2F;&#x2F;处理消息比较慢 一秒处理一个消息 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;消费者2: &quot;+new String(body)); &#125;&#125;); 4.测试结果 image-20200314223242058 image-20200314223302207 总结:默认情况下，RabbitMQ将按顺序将每个消息发送给下一个使用者。平均而言，每个消费者都会收到相同数量的消息。这种分发消息的方式称为循环。 5.消息自动确认机制 Doing a task can take a few seconds. You may wonder what happens if one of the consumers starts a long task and dies with it only partly done. With our current code, once RabbitMQ delivers a message to the consumer it immediately marks it for deletion. In this case, if you kill a worker we will lose the message it was just processing. We’ll also lose all the messages that were dispatched to this particular worker but were not yet handled. But we don’t want to lose any tasks. If a worker dies, we’d like the task to be delivered to another worker. 123456789channel.basicQos(1);&#x2F;&#x2F;一次只接受一条未确认的消息&#x2F;&#x2F;参数2:关闭自动确认消息channel.basicConsume(&quot;hello&quot;,false,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者1: &quot;+new String(body)); channel.basicAck(envelope.getDeliveryTag(),false);&#x2F;&#x2F;手动确认消息 &#125;&#125;); 设置通道一次只能消费一个消息 关闭消息的自动确认,开启手动确认消息 image-20200314230412178 image-20200314230423280 4.5 第三种模型(fanout)fanout 扇出 也称为广播 image-20191126213115873 在广播模式下，消息发送流程是这样的： 可以有多个消费者 每个消费者有自己的queue（队列） 每个队列都要绑定到Exchange（交换机） 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定。 交换机把消息发送给绑定过的所有队列 队列的消费者都能拿到消息。实现一条消息被多个消费者消费 1. 开发生产者1234&#x2F;&#x2F;声明交换机channel.exchangeDeclare(&quot;logs&quot;,&quot;fanout&quot;);&#x2F;&#x2F;广播 一条消息多个消费者同时消费&#x2F;&#x2F;发布消息channel.basicPublish(&quot;logs&quot;,&quot;&quot;,null,&quot;hello&quot;.getBytes()); 2. 开发消费者-112345678910111213&#x2F;&#x2F;绑定交换机channel.exchangeDeclare(&quot;logs&quot;,&quot;fanout&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;将临时队列绑定exchangechannel.queueBind(queue,&quot;logs&quot;,&quot;&quot;);&#x2F;&#x2F;处理消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者1: &quot;+new String(body)); &#125;&#125;); 3. 开发消费者-212345678910111213&#x2F;&#x2F;绑定交换机channel.exchangeDeclare(&quot;logs&quot;,&quot;fanout&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;将临时队列绑定exchangechannel.queueBind(queue,&quot;logs&quot;,&quot;&quot;);&#x2F;&#x2F;处理消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者2: &quot;+new String(body)); &#125;&#125;); 4.开发消费者-312345678910111213&#x2F;&#x2F;绑定交换机channel.exchangeDeclare(&quot;logs&quot;,&quot;fanout&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;将临时队列绑定exchangechannel.queueBind(queue,&quot;logs&quot;,&quot;&quot;);&#x2F;&#x2F;处理消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者3: &quot;+new String(body)); &#125;&#125;); 5. 测试结果 image-20200315180653207 image-20200315180708489 image-20200315180728035 4.6 第四种模型(Routing)4.6.1 Routing 之订阅模型-Direct(直连)在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。 在Direct模型下： 队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key） 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 RoutingKey。 Exchange不再把消息交给每一个绑定的队列，而是根据消息的Routing Key进行判断，只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息 流程: image-20191126220145375 图解： P：生产者，向Exchange发送消息，发送消息时，会指定一个routing key。 X：Exchange（交换机），接收生产者的消息，然后把消息递交给 与routing key完全匹配的队列 C1：消费者，其所在队列指定了需要routing key 为 error 的消息 C2：消费者，其所在队列指定了需要routing key 为 info、error、warning 的消息 1. 开发生产者12345&#x2F;&#x2F;声明交换机 参数1:交换机名称 参数2:交换机类型 基于指令的Routing key转发channel.exchangeDeclare(&quot;logs_direct&quot;,&quot;direct&quot;);String key &#x3D; &quot;&quot;;&#x2F;&#x2F;发布消息channel.basicPublish(&quot;logs_direct&quot;,key,null,(&quot;指定的route key&quot;+key+&quot;的消息&quot;).getBytes()); 2.开发消费者-112345678910111213141516 &#x2F;&#x2F;声明交换机channel.exchangeDeclare(&quot;logs_direct&quot;,&quot;direct&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;绑定队列和交换机channel.queueBind(queue,&quot;logs_direct&quot;,&quot;error&quot;);channel.queueBind(queue,&quot;logs_direct&quot;,&quot;info&quot;);channel.queueBind(queue,&quot;logs_direct&quot;,&quot;warn&quot;);&#x2F;&#x2F;消费消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者1: &quot;+new String(body)); &#125;&#125;); 3.开发消费者-212345678910111213&#x2F;&#x2F;声明交换机channel.exchangeDeclare(&quot;logs_direct&quot;,&quot;direct&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;绑定队列和交换机channel.queueBind(queue,&quot;logs_direct&quot;,&quot;error&quot;);&#x2F;&#x2F;消费消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者2: &quot;+new String(body)); &#125;&#125;); 4.测试生产者发送Route key为error的消息时 image-20200316102613933 image-20200316102627912 5.测试生产者发送Route key为info的消息时 image-20200316102925740 image-20200316102947326 4.6.2 Routing 之订阅模型-TopicTopic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！这种模型Routingkey 一般都是由一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert image-20191127121900255 123456# 统配符 * (star) can substitute for exactly one word. 匹配不多不少恰好1个词 # (hash) can substitute for zero or more words. 匹配一个或多个词# 如: audit.# 匹配audit.irs.corporate或者 audit.irs 等 audit.* 只能匹配 audit.irs 1.开发生产者12345&#x2F;&#x2F;生命交换机和交换机类型 topic 使用动态路由(通配符方式)channel.exchangeDeclare(&quot;topics&quot;,&quot;topic&quot;);String routekey &#x3D; &quot;user.save&quot;;&#x2F;&#x2F;动态路由key&#x2F;&#x2F;发布消息channel.basicPublish(&quot;topics&quot;,routekey,null,(&quot;这是路由中的动态订阅模型,route key: [&quot;+routekey+&quot;]&quot;).getBytes()); 2.开发消费者-1Routing Key中使用*通配符方式 1234567891011121314 &#x2F;&#x2F;声明交换机channel.exchangeDeclare(&quot;topics&quot;,&quot;topic&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;绑定队列与交换机并设置获取交换机中动态路由channel.queueBind(queue,&quot;topics&quot;,&quot;user.*&quot;);&#x2F;&#x2F;消费消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者1: &quot;+new String(body)); &#125;&#125;); 3.开发消费者-2Routing Key中使用#通配符方式 1234567891011121314&#x2F;&#x2F;声明交换机channel.exchangeDeclare(&quot;topics&quot;,&quot;topic&quot;);&#x2F;&#x2F;创建临时队列String queue &#x3D; channel.queueDeclare().getQueue();&#x2F;&#x2F;绑定队列与交换机并设置获取交换机中动态路由channel.queueBind(queue,&quot;topics&quot;,&quot;user.#&quot;);&#x2F;&#x2F;消费消息channel.basicConsume(queue,true,new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者2: &quot;+new String(body)); &#125;&#125;); 4.测试结果 image-20200316113935785 image-20200316114000459 SpringBoot中使用RabbitMQ 5.0 搭建初始环境1. 引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 2. 配置配置文件123456789spring: application: name: springboot_rabbitmq rabbitmq: host: 10.15.0.9 port: 5672 username: ems password: 123 virtual-host: &#x2F;ems RabbitTemplate 用来简化操作 使用时候直接在项目中注入即可使用 5.1 第一种hello world模型使用 ##### 开发生产者 ```java @Autowired private RabbitTemplate rabbitTemplate; @Test public void testHello(){ rabbitTemplate.convertAndSend(“hello”,”hello world”); } ``` ##### 开发消费者 ```java @Component @RabbitListener(queuesToDeclare = @Queue(“hello”)) public class HelloCustomer { @RabbitHandler public void receive1(String message){ System.out.println(&quot;message = &quot; + message); }} ``` 5.2 第二种work模型使用 ##### 开发生产者 ```java @Autowired private RabbitTemplate rabbitTemplate; @Test public void testWork(){ for (int i = 0; i &lt; 10; i++) { rabbitTemplate.convertAndSend(“work”,”hello work!”); } } ``` ##### 开发消费者 ```java @Component public class WorkCustomer { @RabbitListener(queuesToDeclare = @Queue(“work”)) public void receive1(String message){ System.out.println(“work message1 = “ + message); } @RabbitListener(queuesToDeclare = @Queue(&quot;work&quot;)) public void receive2(String message){ System.out.println(&quot;work message2 = &quot; + message); }} ``` 说明:默认在Spring AMQP实现中Work这种方式就是公平调度,如果需要实现能者多劳需要额外配置 5.3 Fanout 广播模型 ##### 开发生产者 ```java @Autowired private RabbitTemplate rabbitTemplate; @Test public void testFanout() throws InterruptedException { rabbitTemplate.convertAndSend(“logs”,””,”这是日志广播”); } ``` ##### 开发消费者 ```java @Component public class FanoutCustomer { @RabbitListener(bindings = @QueueBinding( value = @Queue, exchange = @Exchange(name=&quot;logs&quot;,type = &quot;fanout&quot;) )) public void receive1(String message){ System.out.println(&quot;message1 = &quot; + message); } @RabbitListener(bindings = @QueueBinding( value = @Queue, //创建临时队列 exchange = @Exchange(name=&quot;logs&quot;,type = &quot;fanout&quot;) //绑定交换机类型 )) public void receive2(String message){ System.out.println(&quot;message2 = &quot; + message); }} ``` 5.4 Route 路由模型 ##### 开发生产者 ```java @Autowired private RabbitTemplate rabbitTemplate; @Test public void testDirect(){ rabbitTemplate.convertAndSend(“directs”,”error”,”error 的日志信息”); } ``` ##### 开发消费者 ```java @Component public class DirectCustomer { @RabbitListener(bindings ={ @QueueBinding( value = @Queue(), key={&quot;info&quot;,&quot;error&quot;}, exchange = @Exchange(type = &quot;direct&quot;,name=&quot;directs&quot;) )}) public void receive1(String message){ System.out.println(&quot;message1 = &quot; + message); } @RabbitListener(bindings ={ @QueueBinding( value = @Queue(), key={&quot;error&quot;}, exchange = @Exchange(type = &quot;direct&quot;,name=&quot;directs&quot;) )}) public void receive2(String message){ System.out.println(&quot;message2 = &quot; + message); }} ``` 5.5 Topic 订阅模型(动态路由模型) ##### 开发生产者 ```java @Autowired private RabbitTemplate rabbitTemplate; //topic @Test public void testTopic(){ rabbitTemplate.convertAndSend(“topics”,”user.save.findAll”,”user.save.findAll 的消息”); } ``` ##### 开发消费者 ```java @Component public class TopCustomer { @RabbitListener(bindings = { @QueueBinding( value = @Queue, key = {“user.*“}, exchange = @Exchange(type = “topic”,name = “topics”) ) }) public void receive1(String message){ System.out.println(“message1 = “ + message); } @RabbitListener(bindings = { @QueueBinding( value = @Queue, key = {&quot;user.#&quot;}, exchange = @Exchange(type = &quot;topic&quot;,name = &quot;topics&quot;) ) }) public void receive2(String message){ System.out.println(&quot;message2 = &quot; + message); }} ``` MQ的应用场景 6.1 异步处理场景说明：用户注册后，需要发注册邮件和注册短信,传统的做法有两种 1.串行的方式 2.并行的方式 串行方式: 将注册信息写入数据库后,发送注册邮件,再发送注册短信,以上三个任务全部完成后才返回给客户端。 这有一个问题是,邮件,短信并不是必须的,它只是一个通知,而这种做法让客户端等待没有必要等待的东西. 这里写图片描述 并行方式:将注册信息写入数据库后,发送邮件的同时,发送短信,以上三个任务完成后,返回给客户端,并行的方式能提高处理的时间。 这里写图片描述 消息队列:假设三个业务节点分别使用50ms,串行方式使用时间150ms,并行使用时间100ms。虽然并行已经提高的处理时间,但是,前面说过,邮件和短信对我正常的使用网站没有任何影响，客户端没有必要等着其发送完成才显示注册成功,应该是写入数据库后就返回. 消息队列: 引入消息队列后，把发送邮件,短信不是必须的业务逻辑异步处理 img 由此可以看出,引入消息队列后，用户的响应时间就等于写入数据库的时间+写入消息队列的时间(可以忽略不计),引入消息队列后处理后,响应时间是串行的3倍,是并行的2倍。 6.2 应用解耦场景：双11是购物狂节,用户下单后,订单系统需要通知库存系统,传统的做法就是订单系统调用库存系统的接口. 这里写图片描述 这种做法有一个缺点: 当库存系统出现故障时,订单就会失败。 订单系统和库存系统高耦合. 引入消息队列 这里写图片描述 订单系统:用户下单后,订单系统完成持久化处理,将消息写入消息队列,返回用户订单下单成功。 库存系统:订阅下单的消息,获取下单消息,进行库操作。 就算库存系统出现故障,消息队列也能保证消息的可靠投递,不会导致消息丢失. 6.3 流量削峰场景: 秒杀活动，一般会因为流量过大，导致应用挂掉,为了解决这个问题，一般在应用前端加入消息队列。 作用: 1.可以控制活动人数，超过此一定阀值的订单直接丢弃(我为什么秒杀一次都没有成功过呢^^) 2.可以缓解短时间的高流量压垮应用(应用程序按自己的最大处理能力获取订单) 1.用户的请求,服务器收到之后,首先写入消息队列,加入消息队列长度超过最大值,则直接抛弃用户请求或跳转到错误页面. 2.秒杀业务根据消息队列中的请求信息，再做后续处理. RabbitMQ的集群 7.1 集群架构7.1.1 普通集群(副本集群) All data/state required for the operation of a RabbitMQ broker is replicated across all nodes. An exception to this are message queues, which by default reside on one node, though they are visible and reachable from all nodes. To replicate queues across nodes in a cluster –摘自官网 默认情况下:RabbitMQ代理操作所需的所有数据/状态都将跨所有节点复制。这方面的一个例外是消息队列，默认情况下，消息队列位于一个节点上，尽管它们可以从所有节点看到和访问 ##### 架构图 image-20200320094147471 核心解决问题: `当集群中某一时刻master节点宕机,可以对Quene中信息,进行备份` ##### 集群搭建 ```markdown # 0.集群规划 node1: 10.15.0.3 mq1 master 主节点 node2: 10.15.0.4 mq2 repl1 副本节点 node3: 10.15.0.5 mq3 repl2 副本节点 # 1.克隆三台机器主机名和ip映射 vim /etc/hosts加入: 10.15.0.3 mq1 10.15.0.4 mq2 10.15.0.5 mq3 node1: vim /etc/hostname 加入: mq1 node2: vim /etc/hostname 加入: mq2 node3: vim /etc/hostname 加入: mq3 # 2.三个机器安装rabbitmq,并同步cookie文件,在node1上执行: scp /var/lib/rabbitmq/.erlang.cookie root@mq2:/var/lib/rabbitmq/ scp /var/lib/rabbitmq/.erlang.cookie root@mq3:/var/lib/rabbitmq/ # 3.查看cookie是否一致: node1: cat /var/lib/rabbitmq/.erlang.cookie node2: cat /var/lib/rabbitmq/.erlang.cookie node3: cat /var/lib/rabbitmq/.erlang.cookie # 4.后台启动rabbitmq所有节点执行如下命令,启动成功访问管理界面: rabbitmq-server -detached # 5.在node2和node3执行加入集群命令: 1.关闭 rabbitmqctl stop_app 2.加入集群 rabbitmqctl join_cluster rabbit@mq1 3.启动服务 rabbitmqctl start_app # 6.查看集群状态,任意节点执行: rabbitmqctl cluster_status # 7.如果出现如下显示,集群搭建成功: Cluster status of node rabbit@mq3 … [{nodes,[{disc,[rabbit@mq1,rabbit@mq2,rabbit@mq3]}]}, {running_nodes,[rabbit@mq1,rabbit@mq2,rabbit@mq3]}, {cluster_name,&lt;“rabbit@mq1”&gt;}, {partitions,[]}, {alarms,[{rabbit@mq1,[]},{rabbit@mq2,[]},{rabbit@mq3,[]}]}] # 8.登录管理界面,展示如下状态: ``` image-20200320095613586 markdown # 9.测试集群在node1上,创建队列 image-20200320095743935 markdown # 10.查看node2和node3节点: image-20200320095827688 image-20200320095843370 markdown # 11.关闭node1节点,执行如下命令,查看node2和node3: rabbitmqctl stop_app image-20200320100000347 image-20200320100010968 7.1.2 镜像集群 This guide covers mirroring (queue contents replication) of classic queues –摘自官网 By default, contents of a queue within a RabbitMQ cluster are located on a single node (the node on which the queue was declared). This is in contrast to exchanges and bindings, which can always be considered to be on all nodes. Queues can optionally be made mirrored across multiple nodes. –摘自官网 镜像队列机制就是将队列在三个节点之间设置主从关系，消息会在三个节点之间进行自动同步，且如果其中一个节点不可用，并不会导致消息丢失或服务不可用的情况，提升MQ集群的整体高可用性。 ##### 集群架构图 image-20200320113423235 ##### 配置集群架构 ```markdown # 0.策略说明 rabbitmqctl set_policy [-p ] [–priority ] [–apply-to ] -p Vhost： 可选参数，针对指定vhost下的queue进行设置 Name: policy的名称 Pattern: queue的匹配模式(正则表达式) Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode ha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes all：表示在集群中所有的节点上进行镜像 exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定 nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定 ha-params：ha-mode模式需要用到的参数 ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manual priority：可选参数，policy的优先级 # 1.查看当前策略 rabbitmqctl list_policies # 2.添加策略 rabbitmqctl set_policy ha-all ‘^hello’ ‘{“ha-mode”:”all”,”ha-sync-mode”:”automatic”}’ 说明:策略正则表达式为 “^” 表示所有匹配所有队列名称 ^hello:匹配hello开头队列 # 3.删除策略 rabbitmqctl clear_policy ha-all # 4.测试集群 ```","tags":[]},{"title":"FastDfs详解","date":"2020-07-14T03:06:07.064Z","path":"2020/07/14/FastDfs详解/","text":"FastDfs介绍分布式文件系统静态资源服务器 图片服务器(在分布式环境中，部署多个同样的系统可以共享。多个不一样的系统也可以共 享资源)。 介绍什么是FastDFS FastDFS是用c语言编写的一款开源的分布式文件系统。FastDFS为互 联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并 注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文 件服务器集群提供文件上传、下载等服务。 FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存 储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问 题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。 https://baike.baidu.com/item/fastdfs 和之前对比，把上传的位置做了变化。这次把图片上传到远程的图片服务器。分布式共享。 流程 文件上传时序图：(按照时间的请求顺序) 在存储服务器上存储了具体的内容，返回给客户端的只是存储的地址， 以后就拿这个远程的地址就可以访问到文件了。 下载文件时序图 下载案例：http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.13/bin/apachetomcat-9.0.13.zip有地址，部署在web服务器，就支持直接下载。开源地址：https://github.com/happyfish100 FastDfs安装 FastDfs安装安装一台虚拟机来模拟，一个Tracker、一个Storage服务。配和nginx访问图片。 (因为需要对外访问，最后可以通过域名访问到图片。)https://www.baidu.com/img/bd_logo1.png 下载:https://github.com/happyfish100 初始环境所需软件: 链接 https://pan.baidu.com/s/1DcUH0TngCiR2LAsLxHWZIg 提取码 mfdp 软件上传： 在线安装libevent工具包：确认是否安装： 1rpm -qa | grep libevent （已安装不需要装,没有安装需要装） 1yum -y install libevent 安装libfastcommon工具包解压缩: 1unzip libfastcommon-master.zip 若unzip命令没找到: 123yum install -y unzip zip.&#x2F;make.sh.&#x2F;make.sh install 若32位目录中没有libfastcommon.so文件，就把/usr/lib64/libfastcommon.so文件向/usr/lib/下复制一份（新版红色框部分标示32位、64位目录都已安装。） 解压： 编译与安装： 观察：可以兼容32,64位系统 Tracker服务安装安装Tracker服务,这只是一个监听服务。1)解压缩: 1unzip fastdfs-master.zip 2) 1.&#x2F;make.sh 3) 1.&#x2F;make.sh install :安装后在/usr/bin/目录下有以fdfs开头的文件都是编译出来的。配置文件都放到/etc/fdfs文件夹4)把/opt/qf/fastdfs/fastdfs-master/conf目录下的所有的配置文件都复制到/etc/fdfs下(从源码的配置文件/opt/qf/fastdfs-soft/fastdfsmaster/conf/*中复制)。 1cp &#x2F;opt&#x2F;qf&#x2F;fastdfs&#x2F;fastdfs-master&#x2F;conf&#x2F;* &#x2F;etc&#x2F;fdfs&#x2F; 5)配置tracker服务。修改/ etc/fdfs /tracker.conf文件。base_path=/home/shuju/fastdfs[手动创建目录]http.server_port=856)启动tracker。 1&#x2F;usr&#x2F;bin&#x2F;fdfs_trackerd &#x2F;etc&#x2F;fdfs&#x2F;tracker.conf 重启使用命令： 1&#x2F;usr&#x2F;bin&#x2F;fdfs_trackerd &#x2F;etc&#x2F;fdfs&#x2F;tracker.conf 1restart Storage服务安装安装storage服务,这个就是真正的存储服务。如果是在不同的服务器安装，第三步的1~4需要重新执行。这里我们在同样一台服务器，不再需要对源码进行重复的编译和安装,仅仅只需要配置storage服务。修改/ etc/fdfs /storage.conf文件 Storage存储和日志存放路径:base_path=/home/shuju/fastdfs图片保持路径: store_path0=/home/shuju/fastdfs指定Tracker服务器: tracker_server=101.21.26.229:22122(阿里云使用外网IP,正常公司内部的正式服务器也只有内网IP)http.server_port=85 # 此处需要和后面 nginx 监听端口保持一致启动storage服务启动： 1&#x2F;usr&#x2F;bin&#x2F;fdfs_storaged &#x2F;etc&#x2F;fdfs&#x2F;storage.conf 日志/home/shuju/fdfs/logs/storaged.log 外网若链接不成功改内网IP重启: 1&#x2F;usr&#x2F;bin&#x2F;fdfs_storaged &#x2F;etc&#x2F;fdfs&#x2F;storage.conf 1restart 链接成功,测试服务测试需要使用客户端的配置文件，所以需要修改配置文件/etc/fdfs/client.conf 客户端日志保持base_path=/home/shuju/fastdfs指定Tracker服务器: tracker_server= 101.21.26.229:22122(外网IP)http.tracker_server_port=85 (配置nginx) 测试指令一：指令的位置:/usr/bin上传图片： 1.&#x2F;fdfs_upload_file &#x2F;etc&#x2F;fdfs&#x2F;client.conf &#x2F;etc&#x2F;fdfs&#x2F;anti-steal.jpg 存储地址：group1/M00/00/00/rBGMA1q4VqqATqNmAABdrZgsqUU938.jpg 真实地址：服务器存储地址:/home/shuju/fastdfs/data/00/00 测试指令二：上传图片： 1.&#x2F;fdfs_test &#x2F;etc&#x2F;fdfs&#x2F;client.conf upload &#x2F;etc&#x2F;fdfs&#x2F;anti-steal.jpg 显示有完整url ：http://192.168.132.134:85/group1/M00/00/00/wKiEhlvUNWWAAjA5AAFl0YAhvnQ243.jpg这个路径是后来可以通过域名的方式直接访问 注意：防火墙放行：22122 23000 两个端口 通过java程序实现上传下载具体代码: https://github.com/SchoderZhao/fastdfsDemo","tags":[]},{"title":"Spring事务传播行为种类","date":"2020-06-17T02:33:11.398Z","path":"2020/06/17/Spring事务传播行为种类/","text":"title: Spring事务传播行为种类date: 2020-06-17 10:33:11 tags:SprigSpring在TransactionDefinition接口中规定了7种类型的事务传播行为，它们规定了事务方法和事务方法发生嵌套调用时事务如何进行传播： 事务传播行为类型 说明 PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 当使用PROPAGATION_NESTED时，底层的数据源必须基于JDBC 3.0，并且实现者需要支持保存点事务机制。 @Transactional(propagation=Propagation.REQUIRED) 事务传播行为种类（注解方式）","tags":[]},{"title":"git使用","date":"2020-06-16T08:55:30.409Z","path":"2020/06/16/git使用/","text":"git 基本操作1、创建一个项目 2、打开项目 在项目目录下右键单击–打开 git bash 3、初始化项目仓库 创建项目仓库 命令 ： git init git config –global user.name &lt;名字&gt; ———&gt;:配置用户名 git config –global user.email &lt;邮箱&gt;———&gt;：配置邮箱 git config –list ———&gt;：查看配置信息 git config –global user.name ———&gt;：查看用户名 git config –global user.email ——–&gt; :查看邮箱 git status 查看文件是否被git管理 4、添加文件 git add 文件名 一次只能添加一个文件 全部添加 ： 1git add ./--all/-A/* 5、提交 git commit -m”日志描述” 6、项目文件内容如果有变动 先 git add . 再 git commit -m”日志” 7、git log 查看项目日志 8、回退操作 git reset –hard 前六位编码 9、恢复手动删除的文件 git checkout 提交生成码 文件名 分支操作 ：1、查看分支 git branch 2、创建分支 git branch 分支名 3、切换分支 git checkout 分支名 4、删除分支 git branch -d 分支名 5、合并分支 git merge 分支名 多人协作开发(接下来用张三、李四、CTO三人来演示工作中的流程)： 1、张三克隆文件：git clone &lt;地址&gt; 文件夹名称 2、李四克隆文件：git clone &lt;地址&gt; 文件夹名称 3、张三在开发过程中需要解决BUG 4、李四在开发过程中需要开发新的功能 张三解决BUG并提交文件：1、创建子分支：git branch zhangsan 2、切换子分支：git checkout zhangsan 3、提交到暂存区：git add index.html 4、提交到版本库：git commit -m “张三提交” 5、关联远程分支：git push –set-upstream origin zhangsan (这一步只需第一次的时候这样做即可，第二次修改文件的时候就可以直接执行第6步) 6、提交文件：git push CTO合并文件：1、更新本地的分支：git fetch –all 2、切换子分支：git checkout zhangsan 3、切换主分支：git checkout master 4、合并文件：git merge zhangsan (：wq 按下回车) 5、提交到远端：git push 6、删除子分支：git checkout -d zhangsan (不需要操作 ) 李四开发新的功能，但是李四的文件还是以前有bug的文件，因此我们需要最新的代码：1、创建并切换子分支：git checkout -b lisi fle 2、将开发好的新功能提交到版本库：git add index.html git commit -m “李四提交” 3、切换主分支：git checkout master 4、将远端最新的代码拉取下来：git pull 5、切换子分支：git checkout lisi 6、合并主分支文件：git merge master 7、退出文件：esc 输入wq 8、提交到远端：git push –set-upstream origin lisi","tags":[]},{"title":"Maven中scope标签作用","date":"2020-06-16T08:41:12.055Z","path":"2020/06/16/Maven中scope标签作用/","text":"Maven中scope标签作用scope 是用来限制 dependency 的作用范围的，影响 maven 项目在各个生命周期时导入的 package 的状态，主要管理依赖的部署。 scope 的作用范围：（1）compile：默认值，适用于所有阶段（表明该 jar 包在编译、运行以及测试中路径均可见），并且会随着项目一起发布。 （2）test：只在测试时使用，用于编译和运行测试代码，不会随项目发布。 （3）runtime：无需参与项目的编译，不过后期的测试和运行周期需要其参与，与 compile 相比，跳过了编译。如 JDBC 驱动，适用运行和测试阶段。 （4）provided：编译和测试时有效，但是该依赖在运行时由服务器提供，并且打包时也不会被包含进去。如 servlet-api。 （5）system：类似 provided，需要显式提供包含依赖的jar，不会从 maven 仓库下载，而是从本地文件系统获取，需要添加 systemPath 的属性来定义路径。","tags":[]},{"title":"java","date":"2020-06-15T08:34:57.000Z","path":"2020/06/15/java/","text":"","tags":[]}]